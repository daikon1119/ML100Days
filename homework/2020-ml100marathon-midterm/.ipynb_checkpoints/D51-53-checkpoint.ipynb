{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy, time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import datasets, metrics\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "\n",
    "df_train = pd.read_csv('train_data.csv')\n",
    "df_test = pd.read_csv('test_features.csv')\n",
    "\n",
    "train_Y = df_train['poi']\n",
    "train_Y = train_Y.astype(int)\n",
    "train_num = train_Y.shape[0]\n",
    "\n",
    "\n",
    "names = df_test['name']\n",
    "df_train = df_train.drop(['name', 'poi'] , axis=1)\n",
    "df_test = df_test.drop(['name'] , axis=1)\n",
    "#df = pd.concat([df_train,df_test])\n",
    "#df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#df_train.dtypes.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 Numeric Features : ['bonus', 'deferral_payments', 'deferred_income', 'director_fees', 'exercised_stock_options', 'expenses', 'from_messages', 'from_poi_to_this_person', 'from_this_person_to_poi', 'loan_advances', 'long_term_incentive', 'other', 'restricted_stock', 'restricted_stock_deferred', 'salary', 'shared_receipt_with_poi', 'to_messages', 'total_payments', 'total_stock_value']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#只取 int64, float64 兩種數值型欄位, 存於 num_features 中\n",
    "num_features = []\n",
    "for dtype, feature in zip(df_train.dtypes, df_train.columns):\n",
    "    if dtype == 'float64' or dtype == 'int64':\n",
    "        num_features.append(feature)\n",
    "print(f'{len(num_features)} Numeric Features : {num_features}\\n')\n",
    "\n",
    "# 削減文字型欄位, 只剩數值型欄位\n",
    "df_train = df_train[num_features]\n",
    "df_test = df_test[num_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52382.0\n",
      "251654.0\n"
     ]
    }
   ],
   "source": [
    "#試一些不同填補缺值的方式（D12），搭配標準化\n",
    "def min_max_normalize(x):\n",
    "    x = (( (x - min(x)) / ( max(x) - min(x) ) ) - 0.5) * 2\n",
    "    return x\n",
    "\n",
    "def standard_normalize(x):\n",
    "    x = ( (x - min(x)) / ( max(x) - min(x) ) )\n",
    "    return x\n",
    "\n",
    "def z_transform(x):\n",
    "    x = ( (x - np.mean(x)) / (np.std(x)) )\n",
    "    return x\n",
    "\n",
    "\n",
    "# 空值補 0\n",
    "#'salary', 'other'，空值用平均值\n",
    "for feature in num_features:  \n",
    "    if feature=='salary' or feature=='other':\n",
    "        # 得到 median \n",
    "        mid = np.median(df_train[~df_train[feature].isnull()][feature])\n",
    "        print (mid)\n",
    "        #df[feature] = df[feature].fillna(df[feature].mean())\n",
    "        df_train[feature] = df_train[feature].fillna(mid)\n",
    "    else:\n",
    "        df_train[feature] = df_train[feature].fillna(0)\n",
    "    df_train[feature] = standard_normalize(df_train[feature])\n",
    "\n",
    "#標準化\n",
    "#df = StandardScaler().fit_transform(df)\n",
    "\n",
    "    \n",
    "#一起做完補缺植和標準化後，再分回去train and test\n",
    "#df_train=df[:train_num]\n",
    "#df_test=df[train_num:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113,)\n",
      "other\n",
      "Identified outliers: 1\n",
      "data_mean:  0.028326011232036503\n",
      "data_std:  0.10216073156369916\n",
      "outliers:  [1.0]\n",
      "total_payments\n",
      "Identified outliers: 3\n",
      "data_mean:  0.012516408464073092\n",
      "data_std:  0.016784447305329055\n",
      "outliers:  [0.08384253915996144, 0.10067379142018949, 0.08118030904136705]\n",
      "(109,)\n"
     ]
    }
   ],
   "source": [
    "#自己認為outliner的features，將outliner移除\n",
    "\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "print (train_Y.shape)\n",
    "#outliers_index=[]        \n",
    "outliner_features = [ 'other', 'total_payments']\n",
    "for feature in outliner_features:\n",
    "    print (feature)\n",
    "    feature_data=list(df_train[feature])\n",
    "    data_mean, data_std = mean(feature_data), std(feature_data)\n",
    "    cut_off = data_std * 3\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "    outliers = [x for x in feature_data if x < lower or x > upper]\n",
    "    '''\n",
    "    for outlier in outliers:\n",
    "        #print (outlier)\n",
    "        #print(df[df['bonus']==outlier].index.values)\n",
    "        outliers_index.append(df[df['bonus']==outlier].index.values[0])\n",
    "    outliers_removed = [x for x in bonus if x >= lower and x <= upper]\n",
    "    '''\n",
    "\n",
    "    keep_indexs = (df_train[feature]> lower) & (df_train[feature]< upper)\n",
    "    df_train = df_train[keep_indexs]\n",
    "    train_Y = train_Y[keep_indexs]\n",
    "\n",
    "\n",
    "    print('Identified outliers: %d' % len(outliers))\n",
    "    print (\"data_mean: \".format(), data_mean)\n",
    "    print (\"data_std: \".format(),  data_std)\n",
    "    #print (\"cut_off\" .format(),  cut_off)\n",
    "    #print (\"lower: \" .format(),  lower)\n",
    "    #print (\"upper: \" .format(),  upper)\n",
    "    print (\"outliers: \" .format(),  outliers)\n",
    "    #print (\"outliers_index: \" .format(),  outliers_index)\n",
    "\n",
    "print (train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor feature in num_features:  \\n    if feature!='salary' and feature!='other':\\n        mid = np.median(df_train[~df_train[feature].isnull()][feature])\\n        df_train[feature]=df_train[feature].replace(0, mid)\\n    df_train[feature] = standard_normalize(df_train[feature])\\n\""
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for feature in num_features:  \n",
    "    if feature!='salary' and feature!='other':\n",
    "        mid = np.median(df_train[~df_train[feature].isnull()][feature])\n",
    "        df_train[feature]=df_train[feature].replace(0, mid)\n",
    "    df_train[feature] = standard_normalize(df_train[feature])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 空值補 0\n",
    "#'salary', 'other'，空值用中位數\n",
    "for feature in num_features:  \n",
    "    if feature=='salary' or feature=='other':\n",
    "        # 得到 median \n",
    "        mid = np.median(df_test[~df_test[feature].isnull()][feature])\n",
    "        df_test[feature] = df_test[feature].fillna(mid)\n",
    "    else:\n",
    "        df_test[feature] = df_test[feature].fillna(0)\n",
    "        \n",
    "    df_test[feature] = standard_normalize(df_test[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-522-c3098fce9dfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for col in num_features:\n",
    "    plt.hist(df[col], 30)\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將資料最大最小化\n",
    "#df = MinMaxScaler().fit_transform(df)\n",
    "\n",
    "train_X = df_train\n",
    "test_X = df_test\n",
    "\n",
    "# 使用三種模型 : 邏輯斯迴歸 / 梯度提升機 / 隨機森林, 參數使用 Random Search 尋找\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "\n",
    "lr = LogisticRegression(tol=0.001, penalty='l2', fit_intercept=True, C=1.0)\n",
    "gdbt = GradientBoostingClassifier(tol=100, subsample=0.75, n_estimators=250, max_features=19,\n",
    "                                  max_depth=6, learning_rate=0.03)\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion = \"gini\", max_depth=None, min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, min_samples_split=2, min_samples_leaf=1, \n",
    "                            max_features='sqrt', max_depth=6, bootstrap=True)\n",
    "\n",
    "\n",
    "#rf = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 設定要訓練的超參數組合\\nn_estimators = [50, 100, 150]\\nmax_depth = [1, 3, 5, 10]\\nparam_grid = dict(n_estimators=n_estimators, max_depth=max_depth)\\n\\n## 建立搜尋物件，放入模型及參數組合字典 (n_jobs=-1 會使用全部 cpu 平行運算)\\ngrid_search = GridSearchCV(rf, param_grid, scoring=\"accuracy\", n_jobs=-1, verbose=1)\\n\\n# 開始搜尋最佳參數\\ngrid_result = grid_search.fit(train_X, train_Y)\\n\\nprint(\"Best Accuracy: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\\n\\nrf_bestparam = RandomForestClassifier(n_estimators=100, min_samples_split=2, min_samples_leaf=1, \\n                                      max_features=\\'sqrt\\', max_depth=6, bootstrap=True)\\n\\n'"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 設定要訓練的超參數組合\n",
    "n_estimators = [50, 100, 150]\n",
    "max_depth = [1, 3, 5, 10]\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "## 建立搜尋物件，放入模型及參數組合字典 (n_jobs=-1 會使用全部 cpu 平行運算)\n",
    "grid_search = GridSearchCV(rf, param_grid, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "\n",
    "# 開始搜尋最佳參數\n",
    "grid_result = grid_search.fit(train_X, train_Y)\n",
    "\n",
    "print(\"Best Accuracy: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "rf_bestparam = RandomForestClassifier(n_estimators=100, min_samples_split=2, min_samples_leaf=1, \n",
    "                                      max_features='sqrt', max_depth=6, bootstrap=True)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.899090909090909"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 邏輯迴歸預測檔 (結果有部分隨機, 請以 Kaggle 計算的得分為準, 以下模型同理)\n",
    "lr.fit(train_X, train_Y)\n",
    "lr_pred = lr.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'name': names, 'poi': lr_pred})\n",
    "sub.to_csv('submit_lr.csv', index=False) \n",
    "cross_val_score(lr,train_X,train_Y,cv=10).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9081818181818182"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 梯度提升機預測檔 \n",
    "gdbt.fit(train_X, train_Y)\n",
    "gdbt_pred = gdbt.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'name': names, 'poi': gdbt_pred})\n",
    "sub.to_csv('submit_gdbt.csv', index=False) \n",
    "cross_val_score(gdbt,train_X,train_Y,cv=10).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7990909090909091"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#決策樹預測檔\n",
    "dt.fit(train_X, train_Y)\n",
    "dt_pred = dt.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'name': names, 'poi': dt_pred})\n",
    "sub.to_csv('submit_dt.csv', index=False)\n",
    "cross_val_score(dt,train_X,train_Y,cv=10).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.899090909090909"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 隨機森林預測檔\n",
    "rf.fit(train_X, train_Y)\n",
    "rf_pred = rf.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'name': names, 'poi': rf_pred})\n",
    "sub.to_csv('submit_rf.csv', index=False) \n",
    "cross_val_score(rf,train_X,train_Y,cv=10).mean()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "XGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['dlopen(/Users/aliceliao/opt/anaconda3/envs/ML100Days/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/aliceliao/opt/anaconda3/envs/ML100Days/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-515-fd3444536e45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mxgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML100Days/lib/python3.7/site-packages/xgboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeviceQuantileDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrabit\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML100Days/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;31m# load the XGBoost library globally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML100Days/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;34m'`brew install libomp` to install OpenMP runtime.\\n'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;34m'  * You are running 32-bit Python on a 64-bit OS\\n'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             'Error message(s): {}\\n'.format(os_error_list))\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_log_callback_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: XGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['dlopen(/Users/aliceliao/opt/anaconda3/envs/ML100Days/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/aliceliao/opt/anaconda3/envs/ML100Days/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_X, train_Y)\n",
    "xgb.score(train_X, train_Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.09257004e-01, 2.40279096e-01, 0.00000000e+00, ...,\n",
       "        5.61887092e-02, 1.07944412e-01, 7.33090455e-01],\n",
       "       [3.16686967e-02, 2.40279096e-01, 9.99107995e-01, ...,\n",
       "        1.11317254e-02, 4.28384543e-01, 8.23659873e-02],\n",
       "       [1.77831912e-01, 2.40279096e-01, 8.68261766e-01, ...,\n",
       "        1.39084385e-01, 5.67077705e-01, 3.34021342e-02],\n",
       "       ...,\n",
       "       [2.62469280e-01, 2.40279096e-01, 8.68261766e-01, ...,\n",
       "        9.46859263e-02, 1.05057782e-02, 1.15910763e-01],\n",
       "       [2.62469280e-01, 2.40279096e-01, 8.68261766e-01, ...,\n",
       "        3.41902995e-02, 6.99102455e-05, 7.33976137e-02],\n",
       "       [1.41291108e-01, 2.40279096e-01, 8.68261766e-01, ...,\n",
       "        1.00000000e+00, 2.26064506e-01, 3.34660417e-02]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
