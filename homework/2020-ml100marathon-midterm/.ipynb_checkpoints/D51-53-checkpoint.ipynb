{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy, time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import datasets, metrics\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "\n",
    "df_train = pd.read_csv('train_data.csv')\n",
    "df_test = pd.read_csv('test_features.csv')\n",
    "\n",
    "df_train['poi'] = df_train['poi'].astype(int)\n",
    "train_Y = df_train['poi']\n",
    "train_num = train_Y.shape[0]\n",
    "\n",
    "\n",
    "names = df_test['name']\n",
    "df_train = df_train.drop(['name', 'poi'] , axis=1)\n",
    "df_test = df_test.drop(['name'] , axis=1)\n",
    "#df = pd.concat([df_train,df_test])\n",
    "#df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#df_train.dtypes.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 Numeric Features : ['bonus', 'deferral_payments', 'deferred_income', 'director_fees', 'exercised_stock_options', 'expenses', 'from_messages', 'from_poi_to_this_person', 'from_this_person_to_poi', 'loan_advances', 'long_term_incentive', 'other', 'restricted_stock', 'restricted_stock_deferred', 'salary', 'shared_receipt_with_poi', 'to_messages', 'total_payments', 'total_stock_value']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#只取 int64, float64 兩種數值型欄位, 存於 num_features 中\n",
    "num_features = []\n",
    "for dtype, feature in zip(df_train.dtypes, df_train.columns):\n",
    "    if dtype == 'float64' or dtype == 'int64':\n",
    "        num_features.append(feature)\n",
    "print(f'{len(num_features)} Numeric Features : {num_features}\\n')\n",
    "\n",
    "# 削減文字型欄位, 只剩數值型欄位\n",
    "df_train = df_train[num_features]\n",
    "df_test = df_test[num_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "#試一些不同填補缺值的方式（D12），搭配標準化\n",
    "def min_max_normalize(x):\n",
    "    x = (( (x - min(x)) / ( max(x) - min(x) ) ) - 0.5) * 2\n",
    "    return x\n",
    "\n",
    "def standard_normalize(x):\n",
    "    x = ( (x - min(x)) / ( max(x) - min(x) ) )\n",
    "    return x\n",
    "\n",
    "def z_transform(x):\n",
    "    x = ( (x - np.mean(x)) / (np.std(x)) )\n",
    "    return x\n",
    "\n",
    "\n",
    "# 空值補 0\n",
    "#'salary', 'other'，空值用平均值\n",
    "for feature in num_features:  \n",
    "    if feature=='salary' or feature=='other':\n",
    "        # 得到 median \n",
    "        mid = np.median(df_train[~df_train[feature].isnull()][feature])\n",
    "        #print (mid)\n",
    "        #df[feature] = df[feature].fillna(df[feature].mean())\n",
    "        df_train[feature] = df_train[feature].fillna(mid)\n",
    "    else:\n",
    "        df_train[feature] = df_train[feature].fillna(0)\n",
    "    df_train[feature] = standard_normalize(df_train[feature])\n",
    "\n",
    "#標準化\n",
    "#df = StandardScaler().fit_transform(df)\n",
    "\n",
    "    \n",
    "#一起做完補缺植和標準化後，再分回去train and test\n",
    "#df_train=df[:train_num]\n",
    "#df_test=df[train_num:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bonus\n",
      "Identified outliers: 2\n",
      "outliers:  [0.875, 1.0]\n",
      "\n",
      "\n",
      "deferral_payments\n",
      "Identified outliers: 2\n",
      "outliers:  [0.9690939632984089, 1.0]\n",
      "\n",
      "\n",
      "deferred_income\n",
      "Identified outliers: 1\n",
      "outliers:  [0.0]\n",
      "\n",
      "\n",
      "director_fees\n",
      "Identified outliers: 0\n",
      "outliers:  []\n",
      "\n",
      "\n",
      "exercised_stock_options\n",
      "Identified outliers: 1\n",
      "outliers:  [0.8957063016414397]\n",
      "\n",
      "\n",
      "expenses\n",
      "Identified outliers: 0\n",
      "outliers:  []\n",
      "\n",
      "\n",
      "from_messages\n",
      "Identified outliers: 1\n",
      "outliers:  [1.0]\n",
      "\n",
      "\n",
      "from_poi_to_this_person\n",
      "Identified outliers: 0\n",
      "outliers:  []\n",
      "\n",
      "\n",
      "from_this_person_to_poi\n",
      "Identified outliers: 2\n",
      "outliers:  [0.9391727493917275, 0.9416058394160584]\n",
      "\n",
      "\n",
      "loan_advances\n",
      "Identified outliers: 1\n",
      "outliers:  [0.004906470407850353]\n",
      "\n",
      "\n",
      "long_term_incentive\n",
      "Identified outliers: 1\n",
      "outliers:  [1.0]\n",
      "\n",
      "\n",
      "other\n",
      "Identified outliers: 1\n",
      "outliers:  [0.25679257764224867]\n",
      "\n",
      "\n",
      "restricted_stock\n",
      "Identified outliers: 1\n",
      "outliers:  [0.9380409863529213]\n",
      "\n",
      "\n",
      "restricted_stock_deferred\n",
      "Identified outliers: 2\n",
      "outliers:  [0.14504687125092047, 0.0]\n",
      "\n",
      "\n",
      "salary\n",
      "Identified outliers: 1\n",
      "outliers:  [1.0]\n",
      "\n",
      "\n",
      "shared_receipt_with_poi\n",
      "Identified outliers: 0\n",
      "outliers:  []\n",
      "\n",
      "\n",
      "to_messages\n",
      "Identified outliers: 1\n",
      "outliers:  [1.0]\n",
      "\n",
      "\n",
      "total_payments\n",
      "Identified outliers: 0\n",
      "outliers:  []\n",
      "\n",
      "\n",
      "total_stock_value\n",
      "Identified outliers: 1\n",
      "outliers:  [0.48545265873774984]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#自己認為outliner的features，將outliner移除\n",
    "\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "#outliers_index=[]        \n",
    "outliner_features = [ 'other', 'total_payments']\n",
    "for feature in num_features:\n",
    "    print (feature)\n",
    "    \n",
    "    feature_data=list(df_train[feature])\n",
    "    data_mean, data_std = mean(feature_data), std(feature_data)\n",
    "    cut_off = data_std * 5\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "    outliers = [x for x in feature_data if x < lower or x > upper]\n",
    "    '''\n",
    "    for outlier in outliers:\n",
    "        #print (outlier)\n",
    "        #print(df[df['bonus']==outlier].index.values)\n",
    "        outliers_index.append(df[df['bonus']==outlier].index.values[0])\n",
    "    outliers_removed = [x for x in bonus if x >= lower and x <= upper]\n",
    "    '''\n",
    "    \n",
    "    #mid = np.median(df_train[~df_train[feature].isnull()][feature])\n",
    "    #for outlier in outliers:\n",
    "    #    df_train[feature].replace({outlier: mid}, inplace = True)\n",
    "    \n",
    "    \n",
    "    keep_indexs = (df_train[feature]> lower) & (df_train[feature]< upper)\n",
    "    #for i in keep_indexs:\n",
    "    #    df_train.replace({feature: i}, mid)\n",
    "        \n",
    "        \n",
    "    df_train = df_train[keep_indexs]\n",
    "    train_Y = train_Y[keep_indexs]\n",
    "\n",
    "\n",
    "    print('Identified outliers: %d' % len(outliers))\n",
    "    #print (\"data_mean: \".format(), data_mean)\n",
    "    #print (\"data_std: \".format(),  data_std)\n",
    "    #print (\"cut_off\" .format(),  cut_off)\n",
    "    #print (\"lower: \" .format(),  lower)\n",
    "    #print (\"upper: \" .format(),  upper)\n",
    "    print (\"outliers: \" .format(),  outliers)\n",
    "    #print (\"outliers_index: \" .format(),  outliers_index)\n",
    "    print (\"\\n\")\n",
    "\n",
    "#print (train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor feature in num_features:  \\n    if feature!='salary' and feature!='other':\\n        mid = np.median(df_train[~df_train[feature].isnull()][feature])\\n        df_train[feature]=df_train[feature].replace(0, mid)\\n    df_train[feature] = standard_normalize(df_train[feature])\\n\""
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for feature in num_features:  \n",
    "    if feature!='salary' and feature!='other':\n",
    "        mid = np.median(df_train[~df_train[feature].isnull()][feature])\n",
    "        df_train[feature]=df_train[feature].replace(0, mid)\n",
    "    df_train[feature] = standard_normalize(df_train[feature])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    95.000000\n",
      "mean      0.097841\n",
      "std       0.273582\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.000000\n",
      "75%       0.000000\n",
      "max       1.000000\n",
      "Name: director_fees, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "'''\n",
    "for col in num_features:\n",
    "    plt.hist(df[col], 30)\n",
    "    plt.title(col)\n",
    "    plt.show()\n",
    "'''\n",
    "print (df_train['director_fees'].describe())\n",
    "df_train['director_fees'].hist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_X, val_X, train_Y, val_Y = train_test_split(df_train, train_Y,\\n                                                    test_size=0.25, random_state=42)\\n\\nprint (\"val_Y:\\n\")\\nprint (val_Y.shape)\\nprint (\"train_Y\\n\")\\nprint (train_Y.shape)\\n'"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_X, val_X, train_Y, val_Y = train_test_split(df_train, train_Y,\n",
    "                                                    test_size=0.25, random_state=42)\n",
    "\n",
    "print (\"val_Y:\\n\")\n",
    "print (val_Y.shape)\n",
    "print (\"train_Y\\n\")\n",
    "print (train_Y.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "#處理df_test\n",
    "for feature in num_features:  \n",
    "    if feature=='salary' or feature=='other':\n",
    "        # 得到 median \n",
    "        mid = np.median(df_test[~df_test[feature].isnull()][feature])\n",
    "        df_test[feature] = df_test[feature].fillna(mid)\n",
    "    else:\n",
    "        df_test[feature] = df_test[feature].fillna(0)\n",
    "        \n",
    "    df_test[feature] = standard_normalize(df_test[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將資料最大最小化\n",
    "#df = MinMaxScaler().fit_transform(df)\n",
    "\n",
    "train_X = df_train\n",
    "test_X = df_test\n",
    "\n",
    "# 使用三種模型 : 邏輯斯迴歸 / 梯度提升機 / 隨機森林, 參數使用 Random Search 尋找\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "\n",
    "lr = LogisticRegression(tol=0.001, penalty='l2', fit_intercept=True, C=1.0)\n",
    "gdbt = GradientBoostingClassifier(tol=100, subsample=0.75, n_estimators=250, max_features=19,\n",
    "                                  max_depth=6, learning_rate=0.03)\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion = \"gini\", max_depth=None, min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, min_samples_split=2, min_samples_leaf=1, \n",
    "                            max_features='sqrt', max_depth=6, bootstrap=True)\n",
    "\n",
    "\n",
    "#rf = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 設定要訓練的超參數組合\\nn_estimators = [50, 100, 150]\\nmax_depth = [1, 3, 5, 10]\\nparam_grid = dict(n_estimators=n_estimators, max_depth=max_depth)\\n\\n## 建立搜尋物件，放入模型及參數組合字典 (n_jobs=-1 會使用全部 cpu 平行運算)\\ngrid_search = GridSearchCV(rf, param_grid, scoring=\"accuracy\", n_jobs=-1, verbose=1)\\n\\n# 開始搜尋最佳參數\\ngrid_result = grid_search.fit(train_X, train_Y)\\n\\nprint(\"Best Accuracy: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\\n\\nrf_bestparam = RandomForestClassifier(n_estimators=100, min_samples_split=2, min_samples_leaf=1, \\n                                      max_features=\\'sqrt\\', max_depth=6, bootstrap=True)\\n\\n'"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 設定要訓練的超參數組合\n",
    "n_estimators = [50, 100, 150]\n",
    "max_depth = [1, 3, 5, 10]\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "## 建立搜尋物件，放入模型及參數組合字典 (n_jobs=-1 會使用全部 cpu 平行運算)\n",
    "grid_search = GridSearchCV(rf, param_grid, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "\n",
    "# 開始搜尋最佳參數\n",
    "grid_result = grid_search.fit(train_X, train_Y)\n",
    "\n",
    "print(\"Best Accuracy: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "rf_bestparam = RandomForestClassifier(n_estimators=100, min_samples_split=2, min_samples_leaf=1, \n",
    "                                      max_features='sqrt', max_depth=6, bootstrap=True)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9055555555555556"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 邏輯迴歸預測檔 (結果有部分隨機, 請以 Kaggle 計算的得分為準, 以下模型同理)\n",
    "lr.fit(train_X, train_Y)\n",
    "lr_pred = lr.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'name': names, 'poi': lr_pred})\n",
    "sub.to_csv('submit_lr.csv', index=False) \n",
    "cross_val_score(lr,train_X,train_Y,cv=10).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8944444444444445"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 梯度提升機預測檔 \n",
    "gdbt.fit(train_X, train_Y)\n",
    "gdbt_pred = gdbt.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'name': names, 'poi': gdbt_pred})\n",
    "sub.to_csv('submit_gdbt.csv', index=False) \n",
    "cross_val_score(gdbt,train_X,train_Y,cv=10).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8522222222222222"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#決策樹預測檔\n",
    "dt.fit(train_X, train_Y)\n",
    "dt_pred = dt.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'name': names, 'poi': dt_pred})\n",
    "sub.to_csv('submit_dt.csv', index=False)\n",
    "cross_val_score(dt,train_X,train_Y,cv=10).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8944444444444445\n"
     ]
    }
   ],
   "source": [
    "# 隨機森林\n",
    "rf.fit(train_X, train_Y)\n",
    "rf_pred = rf.predict_proba(val_X)[:,1]\n",
    "print(cross_val_score(rf,train_X,train_Y,cv=10).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8944444444444445"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 隨機森林預測檔\n",
    "rf.fit(train_X, train_Y)\n",
    "rf_pred = rf.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'name': names, 'poi': rf_pred})\n",
    "sub.to_csv('submit_rf.csv', index=False) \n",
    "cross_val_score(rf,train_X,train_Y,cv=10).mean()\n",
    "\n",
    "\n",
    "#clf.fit(x_train, y_train)\n",
    "#y_pred = clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "XGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['dlopen(/Users/aliceliao/opt/anaconda3/envs/ML100Days/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/aliceliao/opt/anaconda3/envs/ML100Days/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-515-fd3444536e45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mxgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML100Days/lib/python3.7/site-packages/xgboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeviceQuantileDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrabit\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML100Days/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;31m# load the XGBoost library globally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML100Days/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;34m'`brew install libomp` to install OpenMP runtime.\\n'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;34m'  * You are running 32-bit Python on a 64-bit OS\\n'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             'Error message(s): {}\\n'.format(os_error_list))\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_log_callback_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: XGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['dlopen(/Users/aliceliao/opt/anaconda3/envs/ML100Days/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/aliceliao/opt/anaconda3/envs/ML100Days/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_X, train_Y)\n",
    "xgb.score(train_X, train_Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.09257004e-01, 2.40279096e-01, 0.00000000e+00, ...,\n",
       "        5.61887092e-02, 1.07944412e-01, 7.33090455e-01],\n",
       "       [3.16686967e-02, 2.40279096e-01, 9.99107995e-01, ...,\n",
       "        1.11317254e-02, 4.28384543e-01, 8.23659873e-02],\n",
       "       [1.77831912e-01, 2.40279096e-01, 8.68261766e-01, ...,\n",
       "        1.39084385e-01, 5.67077705e-01, 3.34021342e-02],\n",
       "       ...,\n",
       "       [2.62469280e-01, 2.40279096e-01, 8.68261766e-01, ...,\n",
       "        9.46859263e-02, 1.05057782e-02, 1.15910763e-01],\n",
       "       [2.62469280e-01, 2.40279096e-01, 8.68261766e-01, ...,\n",
       "        3.41902995e-02, 6.99102455e-05, 7.33976137e-02],\n",
       "       [1.41291108e-01, 2.40279096e-01, 8.68261766e-01, ...,\n",
       "        1.00000000e+00, 2.26064506e-01, 3.34660417e-02]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
